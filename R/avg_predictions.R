#' Calculate average predictions for target variables in random forest
#'
#' @param marginal_preds Object of class \code{treePredictions} generated by \code{tree_predictions}.
#' @param target.vars Character string of targeted predictor variable names from which to derive predictions.
#' @param equal.wt Character string of external predictor variable names across which equal weighting will be applied.
#' @param wt Character string indicating the type of weighting to be applied to the calculation of mean predictions. See details below.
#' @param interval Numeric values specifying the central proportion of predictions to report. Default is 90%
#' @param verbose Logical. Should extra information be printed?
#'
#' @author Jason Grafmiller
#'
#' @details Calculates the weighted average predictions for a target predictor in random forest model.
#'
#' @return A \code{data.frame} including all combinations of values in \code{target.vars}.
#' \describe{
#' \item{\code{mean_X_prob}}{The mean of model predictions for level X weighted by the marginal distributions across all predictors other than \code{target.vars} and \code{equal.wt}.}
#' \item{\code{lower}}{The lower percentile of model predictions set by \code{interval}.}
#' \item{\code{upper}}{The upper percentile of model predictions set by \code{interval}.}
#' }
#'
#' @references
#'
#' SÃ¶nning, Lukas & Jason Grafmiller. 2022. Seeing the wood for the trees: Predictive margins for random forests. Preprint. \emph{PsyArXiv}. \url{https://doi.org/10.31234/osf.io/jr8yk}.
#'
#' @export
#'
#' @examples
#' \dontrun{
#' # not run
#' library(ranger)
#'
#' rf <- ranger(Species ~ ., iris, probability = T)
#'
#' tree_preds <- tree_predictions(rf, iris)
#'
#' avg_predictions(tree_preds, "Sepal.Length")
#' }
#' @importFrom data.table ":="
avg_predictions <- function(marginal_preds, target.vars, equal.wt = NULL,
                         wt = c("iso", "joint", "all"),
                         interval = c(.05, .95),
                         verbose = TRUE){
  require(data.table)

  if(class(marginal_preds) != "treePredictions") stop(paste(marginal_preds, 'is not of class "treePredictions"'))

  wt <- match.arg(wt)
  n.breaks <- marginal_preds$n.breaks
  pred_vals <- marginal_preds$variable.vals
  mar_table <- marginal_preds$predictions
  data <- marginal_preds$data
  pred_outcome <- paste0(marginal_preds$predicted.outcome, "_pred")

  # Convert data and tables to data.table objects for faster processing
  if(!is.data.table(mar_table)) mar_table <- as.data.table(mar_table)
  if(!is.data.table(data)) data_dt <- as.data.table(data)

  # Get vector of all predictor names
  full_vars <- marginal_preds$variable_names

  # Create version of the data based on the bins ------
  # Get peripheral predictor variables
  peripheral_vars <- full_vars[!(full_vars %in% target.vars)]

  # exclude any external variables
  if(!is.null(equal.wt)) peripheral_vars <- peripheral_vars[!(peripheral_vars %in% equal.wt)]

  if(verbose){
    if(is.null(equal.wt)){
      message("Calculating weighted averages treating ", paste(peripheral_vars, collapse = ", "), " as peripheral variables")
    } else {
      message("Calculating weighted averages treating ", paste(peripheral_vars, collapse = ", "), " as peripheral variables, and ", paste(equal.wt, collapse = ", "), " as unweighted variables.\n")
    }

    if(wt == "iso") {
      message("Weightings of feature combinations are based on their expected frequency derived from their independent marginal distributions in the dataset.")
    } else if(wt == "joint"){
      message("Weightings of feature combinations are based on their observed frequency in the dataset.")
    }
  }

  if(length(peripheral_vars) == 1){
    num_vars <- peripheral_vars[is.numeric(data[, peripheral_vars])]
  } else {
    num_vars <- peripheral_vars[sapply(data[, peripheral_vars], is.numeric)]
  }

  if(length(num_vars) > 0) {
    # Convert numeric columns to factors for merging
    # data_dt[ , (num_vars) := lapply(.SD, as.factor), .SDcols = num_vars]
    binned_d <- copy(data_dt)

    for(i in seq_along(num_vars)){
      v <- num_vars[i]
      vals <- sort(unique(mar_table[, get(v)]))
      cuts <- vals
      cuts[1] <- min(data_dt[, get(v)]) # set min cut at data minimum
      cuts <- c(cuts, max(data_dt[, get(v)])) # set max cut at data maximum
      binned_d[ , (v) := lapply(.SD, function(x) cut(x, cuts, include.lowest=T)), .SDcols = v]
      # now set the levels to the values in the marginal predictions table
      setattr(binned_d[[v]],"levels", as.character(vals))
    }
    mar_table[ , (num_vars) := lapply(.SD, as.factor), .SDcols = num_vars]
  } else {
    binned_d <- data_dt
  }

  # Create dataframe of weights
  if(wt == "joint"){
    count_dt <- ftable(binned_d[, ..peripheral_vars]) |>
      as.data.frame() |>
      as.data.table()
    prop_f <- function(x) x/nrow(data)
    count_dt[, wt := prop_f(Freq)]
    names(count_dt)[1:length(peripheral_vars)] <- peripheral_vars

    # merge data_dt with the the weighting data.table
    mar_table <- merge(mar_table, count_dt, by = peripheral_vars, all.x = TRUE)

  } else if (wt == "iso"){
    # stop("I'm not sure what to do here...")
    # wt_list <- lapply(peripheral_vars, function(x){


    for(i in seq_along(peripheral_vars)){
      p <- peripheral_vars[i]
      df <- as.data.frame(table(binned_d[, get(p)]))
      df$prop <- df$Freq/sum(df$Freq)
      names(df)[1] <- p
      names(df)[2] <- paste0("freq_", p)
      names(df)[3] <- paste0("prop_", p)
      df[, 1] <- as.factor(df[, 1])

      mar_table <- merge(mar_table, df, by = p, all.x = TRUE)
      # return(df)
    }

    mar_table$wt <- apply(
      mar_table[, names(mar_table)[startsWith(names(mar_table), "prop_")], with=FALSE],
      1,
      prod
      )

    # )
    # for(p in seq_along(wt_list)){
    #   mar_table <- merge(mar_table, wt_list[[1]], by = )
    # }
  } else if (wt == "all"){
    count_dt <- ftable(binned_d[, ..full_vars]) |>
      as.data.frame() |>
      as.data.table()
    prop_f <- function(x) x/nrow(data)
    count_dt[, wt := prop_f(Freq)]
    names(count_dt)[1:length(full_vars)] <- full_vars

    # merge data_dt with the the weighting data.table

    mar_table <- merge(mar_table, count_dt, by = full_vars, all.x = TRUE)
  }

  # get the averages
  mar_avg_df <- mar_table[, .(mean_pred = weighted.mean(get(pred_outcome), wt)),
                       by = c(target.vars, "tree")][, .(mean = mean(mean_pred, na.rm = TRUE),
                                                 lower = quantile(mean_pred, interval[1], na.rm = TRUE),
                                                 upper = quantile(mean_pred, interval[2], na.rm = TRUE)),
                                             by = target.vars] |>
    as.data.frame() # convert back to data.frame

  names(mar_avg_df)[names(mar_avg_df) == "mean"] <- paste("mean", pred_outcome, sep = "_")

  if(length(num_tar_vars) == 1){
    num_tar_vars <- target.vars[is.numeric(data[, target.vars])]
  } else {
    num_tar_vars <- target.vars[target.vars %in% target.vars[sapply(data[, target.vars], is.numeric)]]
  }

  if(length(num_tar_vars) > 0) mar_avg_df[num_tar_vars] <- lapply(mar_avg_df[num_tar_vars], function(x) as.numeric(as.character(x))) # convert back to numeric

  return(mar_avg_df)

}
